{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7Mg_iEa3Wu1u",
    "outputId": "0a966df2-4ffc-40ce-f2f8-7b1f839286c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-54c936800203>:19: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(num_heads * self.head_size == embed_dim, \"embed dim and number of heads aren't compatible\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6888 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated exemple sentence: \n",
      " ['tanzania', 'dot', 'refugee', 'backed', 'twisted', 'returning', 'danny', 'warn', 'neat', 'counseling', 'biases', 'non', 'phase', 'jazz', 'driving', 'bipolar', 'beloved', 'potentially', 'disability', 'pond', 'derive', 'speakers', 'underlies', 'bipolar', 'tip', 'connecticut', 'ideally', 'sudan', 'stores', 'period', 'knit', 'nba', 'daylight', 'optimal', 'currents', 'p', 'injured', 'bench', 'download', 'underlies', 'ashamed', 'kentucky', 'opinion', 'existed', 'liked', 'l.a.', 'bj', 'twisted', 'returning', 'unacceptable', 'underlies', 'introduced', 'solitary', 'movement', 'hurricane', 'magazines', 'underlies', 'puzzle', 'infections', 'digging', 'engineering', 'lapse', 'reminds', 'conclusions', 'bus', 'biases', 'receives', 'integration', 'shooting', 'may', 'legacy', 'solitary', 'non', 'april', 'exceptional', 'participants', 'avatar', 'graders', '20', 'dancing', 'cholera', 'underlies', 'a.i.', 'prayer', 'constitution', 'critics', 'operates', 'bleed', 'pit', 'iceland', 'guerrilla', 'poll', 'guerrilla', 'danny', 'shown', 'envelope', 'blend', 'citizens', 'cleaning', 'biases']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:209: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "100%|██████████| 6888/6888 [04:51<00:00, 23.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "epoch 2/10\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6888 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated exemple sentence: \n",
      " ['a', 'black', 'cat', 'and', 'white', 'is', 'beautiful', '.', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [04:55<00:00, 23.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "epoch 3/10\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6888 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated exemple sentence: \n",
      " ['black', 'cat', 'and', 'white', 'and', 'white', 'is', 'cute', '.', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [04:55<00:00, 23.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "epoch 4/10\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6888 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated exemple sentence: \n",
      " ['black', 'cat', 'and', 'white', 'is', 'white', '.', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [04:52<00:00, 23.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "epoch 5/10\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6888 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated exemple sentence: \n",
      " ['black', 'cat', 'and', 'white', 'is', 'cute', '.', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [04:59<00:00, 23.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "epoch 6/10\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6888 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated exemple sentence: \n",
      " ['a', 'cat', 'and', 'white', 'cat', 'is', 'cute', '.', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [04:57<00:00, 23.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "epoch 7/10\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6888 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated exemple sentence: \n",
      " ['a', 'black', 'cat', 'and', 'white', 'is', 'cute', '.', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [04:55<00:00, 23.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "epoch 8/10\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6888 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated exemple sentence: \n",
      " ['a', 'black', 'cat', 'and', 'white', 'is', 'cute', '.', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [04:54<00:00, 23.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "epoch 9/10\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6888 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated exemple sentence: \n",
      " ['black', 'cat', 'and', 'white', 'is', 'cute', '.', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [04:54<00:00, 23.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "epoch 10/10\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6888 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated exemple sentence: \n",
      " ['black', 'cat', 'is', 'cute', '.', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [04:54<00:00, 23.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import IWSLT\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#execute on gpu if available, else on cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#multi-head attention block\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, mask = False):\n",
    "        super().__init__()\n",
    "        #split the embeded word into multiple heads that run in parallel\n",
    "        self.num_heads = num_heads\n",
    "        self.head_size = embed_dim // num_heads\n",
    "        #optionally use mask to hide the next part of the sentence (used for the decoder)\n",
    "        self.mask = mask\n",
    "        assert(num_heads * self.head_size == embed_dim, \"embed dim and number of heads aren't compatible\")\n",
    "        #linear layers\n",
    "        self.lin1 = nn.Linear(self.head_size, self.head_size, bias = False)\n",
    "        self.lin2 = nn.Linear(embed_dim, embed_dim, bias = False)\n",
    "        \n",
    "    def forward(self, queries, keys, values):\n",
    "        b, t2 = queries.size(0), queries.size(1)\n",
    "        h = self.num_heads\n",
    "        d = self.head_size\n",
    "        t = values.size(1)\n",
    "        \n",
    "        #receive queries, keys and values and pass through linear layers\n",
    "        queries = self.lin1(queries.reshape(b, t2, h , d))\n",
    "        keys = self.lin1(keys.reshape(b, t, h , d))\n",
    "        values = self.lin1(values.reshape(b, t, h , d))\n",
    "        \n",
    "        #scaled dot product attention\n",
    "        queries = queries.transpose(1,2).reshape(b * h, t2, d)\n",
    "        keys = keys.transpose(1,2).reshape(b * h, t, d)\n",
    "        matmul1 = torch.bmm(queries, keys.transpose(1,2))\n",
    "        scale = (matmul1 / (d ** (1/2)))\n",
    "        \n",
    "        if self.mask:\n",
    "            indices = torch.triu_indices(t2, t, offset = 1)\n",
    "            scale[:, indices[0], indices[1]] = float('-inf')\n",
    "            \n",
    "        soft = F.softmax(scale, dim=2)\n",
    "        values = values.transpose(1,2).reshape(b *  h, t, d)\n",
    "        matmul2 = torch.bmm(soft, values)\n",
    "        \n",
    "        #concat and linear layer\n",
    "        out = self.lin2(matmul2.reshape(b, h, t2, d).transpose(1, 2).reshape(b, t2, h * d))\n",
    "        \n",
    "        return out\n",
    "\n",
    "#transformer block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, expansion_size, drop = 0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        #use multi-head attention block\n",
    "        self.attentionblock = SelfAttention(self.embed_dim, self.num_heads)\n",
    "        \n",
    "        #feed forward block\n",
    "        self.ff = nn.Sequential(nn.Linear(embed_dim, expansion_size),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(expansion_size, embed_dim))\n",
    "        #normalization layer\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        \n",
    "    def forward(self, queries, keys, values):\n",
    "        \n",
    "        #attention\n",
    "        mha = self.attentionblock(queries, keys, values)\n",
    "        \n",
    "        #add & norm 1 block\n",
    "        addnorm1 = self.norm(queries + self.dropout(mha))\n",
    "        \n",
    "        #feed forward\n",
    "        feedfwd = self.ff(addnorm1)\n",
    "        \n",
    "        #add & norm block\n",
    "        addnorm2 = self.norm(addnorm1 + self.dropout(feedfwd))\n",
    "        \n",
    "        return addnorm2\n",
    "    \n",
    "#encoder block\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, expansion_size, num_layers, dict_size, max_len=100, drop = 0.1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        #word embedding\n",
    "        self.embed = nn.Embedding(dict_size, embed_dim)\n",
    "        \n",
    "        #positional encoding\n",
    "        self.embed_pos = nn.Embedding(max_len, embed_dim)\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        \n",
    "        #tranformer block\n",
    "        self.transformblock = TransformerBlock(embed_dim, num_heads, expansion_size, drop)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        b, t = inp.size()\n",
    "        \n",
    "        #combine tranformer block with embedding and positional encoding\n",
    "        input_embed = self.embed(inp)\n",
    "        pos = torch.arange(t).repeat(b, 1).to(device)\n",
    "        pos_embed = self.embed_pos(pos)\n",
    "        input_pos = self.dropout(pos_embed + input_embed)\n",
    "        out = input_pos\n",
    "        \n",
    "        #make 'n' layers of encoder block\n",
    "        for i in range(self.num_layers):\n",
    "            out = self.transformblock.forward(out, out, out)\n",
    "            \n",
    "        return out\n",
    "\n",
    "#decoder block\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_dim, num_heads, expansion_size, num_layers, dict_size, max_len=100, drop = 0.1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        #word embedding\n",
    "        self.embed = nn.Embedding(dict_size, embed_dim)\n",
    "        \n",
    "        #positional encoding\n",
    "        self.embed_pos = nn.Embedding(max_len, embed_dim)\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        \n",
    "        #attention block with mask\n",
    "        self.attentionblock = SelfAttention(embed_dim, num_heads, mask = True)\n",
    "        \n",
    "        #norm layer\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        #transformer block\n",
    "        self.transformblock = TransformerBlock(embed_dim, num_heads, expansion_size, drop)\n",
    "        self.lin = nn.Linear(embed_dim, dict_size)\n",
    "        \n",
    "    def forward(self, inp, inp_enc):\n",
    "        \n",
    "        #same architecture as the encoder with masked attention and addnorm block added before transformer block\n",
    "        b, t = inp.size()\n",
    "        input_embed = self.embed(inp)\n",
    "        pos = torch.arange(t).repeat(b, 1).to(device)\n",
    "        pos_embed = self.embed_pos(pos)\n",
    "        input_pos = self.dropout(pos_embed + input_embed)\n",
    "        out = input_pos\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            out = self.norm(out + self.dropout(self.attentionblock.forward(out, out, out)))\n",
    "            out = self.transformblock.forward(out, inp_enc, inp_enc)\n",
    "            \n",
    "        out =  self.dropout(self.lin(out))\n",
    "        \n",
    "        return out\n",
    "\n",
    "#complete transformer\n",
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_dim, num_heads, expansion_size, num_layers, src_dict_size, trg_dict_size, max_len=100, drop = 0.1):\n",
    "        super().__init__()\n",
    "        self.enc = Encoder(embed_dim, num_heads, expansion_size, num_layers, src_dict_size, max_len, drop)\n",
    "        self.dec = Decoder(embed_dim, num_heads, expansion_size, num_layers, trg_dict_size, max_len, drop)\n",
    "        \n",
    "    def forward(self, inp, out):\n",
    "        \n",
    "        #combine encoder with decoder\n",
    "        return self.dec.forward(out, self.enc.forward(inp))\n",
    "\n",
    "#function to translate sentence\n",
    "def translate_sentence(sentence, model, french, english, max_len=100):\n",
    "    \n",
    "    #load spacy language module to build vocabulary\n",
    "    spacy_fr = spacy.load(\"fr\")\n",
    "    \n",
    "    #use spacy tokenization function\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.text.lower() for token in spacy_fr(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "        \n",
    "    #insert start and end of sentence tokens\n",
    "    tokens.insert(0, french.init_token)\n",
    "    tokens.append(french.eos_token)\n",
    "    \n",
    "    #convert tokens to indices\n",
    "    text_to_indices = [french.vocab.stoi[tok] for tok in tokens]\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(0).to(device)\n",
    "    \n",
    "    #second param will be start of sentence index\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "    \n",
    "    #for each loop the model will predict the next word in the translated sentence\n",
    "    for i in range(max_len):\n",
    "        \n",
    "        #convert target to tensor\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(0).to(device)\n",
    "        \n",
    "        #predict next word\n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, trg_tensor)\n",
    "        best_guess = output.argmax(2)[:, -1].item()\n",
    "        outputs.append(best_guess)\n",
    "        \n",
    "        \n",
    "        if best_guess == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "    #convert indices into words\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "    \n",
    "    #return sentence without \"start\" and \"end\" tokens\n",
    "    return translated_sentence[1:-1]\n",
    "\n",
    "\n",
    "#load spacy language modules to build vocabularies\n",
    "spacy_fr = spacy.load(\"fr\")\n",
    "spacy_en = spacy.load(\"en\")\n",
    "\n",
    "#use spacy tokenization functions\n",
    "def tokenize_fr(text):\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "\n",
    "french = Field(tokenize=tokenize_fr, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "english = Field(tokenize=tokenize_en, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "#use the ISWLT dataset of TED talks\n",
    "train_data, valid_data, test_data = IWSLT.splits(exts=(\".fr\", \".en\"), fields=(french, english))\n",
    "\n",
    "#build vocabularies\n",
    "french.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "\n",
    "#model hyperparameters\n",
    "embed_dim = 512\n",
    "num_heads = 8\n",
    "expansion_size = 2048\n",
    "num_layers = 3\n",
    "src_dict_size = len(french.vocab)\n",
    "trg_dict_size = len(english.vocab)\n",
    "max_len = 100\n",
    "dropout = 0.1\n",
    "\n",
    "#training hyperparameters\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learn_rate = 0.0003\n",
    "\n",
    "load_model = False\n",
    "save_model = True\n",
    "\n",
    "#use Tensorboard summary writer to plot loss and accuracy during training\n",
    "writer = SummaryWriter(\"runs/loss-plot\")\n",
    "step = 0\n",
    "\n",
    "#use the BucketIterator module to split data into batches sorted by sentence length\n",
    "train_it, valid_it, test_it = BucketIterator.splits((train_data, valid_data, test_data), batch_size=batch_size, sort_within_batch=True, sort_key= lambda x: len(x.src), device=device)\n",
    "\n",
    "#make instance of tranformer model\n",
    "model = Transformer(embed_dim, num_heads, expansion_size, num_layers, src_dict_size, trg_dict_size, max_len=max_len, drop=dropout).to(device)\n",
    "\n",
    "#make optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learn_rate)\n",
    "\n",
    "#get padding index and ignore it when calculating loss\n",
    "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "#can load saved model and optimizer\n",
    "if load_model:\n",
    "    print(\"=> loading checkpoint\")\n",
    "    checkpoint = torch.load(\"my_checkpoint.pth.tar\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    \n",
    "#test sentence\n",
    "sentence = \"un chat noir et blanc est mignon.\"\n",
    "\n",
    "#loop over epochs\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    losses = []\n",
    "    print(f\"epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    #can save model and optimizer in \".tar\" file\n",
    "    if save_model:\n",
    "        print(\"=> saving checkpoint\")\n",
    "        checkpoint = {\"state_dict\":model.state_dict(), \"optimizer\":optimizer.state_dict()}\n",
    "        torch.save(checkpoint, \"my_checkpoint.pth.tar\")\n",
    "        \n",
    "    #test model while training\n",
    "    model.eval()\n",
    "    translated_sentence = translate_sentence(sentence, model, french, english)\n",
    "    print(f\"translated exemple sentence: \\n {translated_sentence}\")\n",
    "    model.train()\n",
    "    \n",
    "    #loop over batches (use tqdm to make a progress bar)\n",
    "    for batch in tqdm(train_it):\n",
    "        \n",
    "        #ignore batches with sentence length over 100\n",
    "        if (batch.src.size(0) > 100) or (batch.trg.size(0) > 100):\n",
    "          continue\n",
    "        \n",
    "        #convert the input and the target into the adquate shape\n",
    "        inp = batch.src.transpose(0, 1).to(device)\n",
    "        trg = batch.trg.transpose(0, 1).to(device)\n",
    "        \n",
    "        #pass them through the model\n",
    "        out = model(inp, trg[:, :-1])\n",
    "        out = out.reshape(-1, out.shape[2])\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        \n",
    "        #zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #calculate the loss backward it\n",
    "        loss = criterion(out, trg)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        \n",
    "        #clip the gradients\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        #add summary writer step\n",
    "        writer.add_scalar(\"Training Loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "        \n",
    "    #calculate the average loss over one epoch\n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    print(\"loss :\",mean_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mZaqgAGL4PJV",
    "outputId": "c1dc55ed-fead-44f9-88ed-48b3fa474b63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (49.6.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
      "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n",
      "Collecting fr_core_news_sm==2.2.5\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7MB)\n",
      "\u001b[K     |████████████████████████████████| 14.7MB 3.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (49.6.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.18.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.7.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.7.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.1.0)\n",
      "Building wheels for collected packages: fr-core-news-sm\n",
      "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-cp36-none-any.whl size=14727027 sha256=1b26a348dc5a015f6b8600ac4539394b2dfb2699b864a19f08984b2c39860907\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-x5xfsulg/wheels/46/1b/e6/29b020e3f9420a24c3f463343afe5136aaaf955dbc9e46dfc5\n",
      "Successfully built fr-core-news-sm\n",
      "Installing collected packages: fr-core-news-sm\n",
      "Successfully installed fr-core-news-sm-2.2.5\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/fr_core_news_sm -->\n",
      "/usr/local/lib/python3.6/dist-packages/spacy/data/fr\n",
      "You can now load the model via spacy.load('fr')\n"
     ]
    }
   ],
   "source": [
    "#install spacy laguage modules\n",
    "!python -m spacy download en\n",
    "!python -m spacy download fr"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled5.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
